### Motion Matching ###
**1.代码修改说明**
我修改了viewer/controller.py中的第269行，将substep改为15。
也就是说answer\_project.py中update\_state输入的平滑过的手柄输入，
是包含现在(第0帧)和未来15,30,45,60,75帧的期望状态。
另外，我把lab2中的decompose_rotation_with_yaxis函数之间拷贝到bvh_loader.py中了。其余部分未做更改，运行时仍然是直接运行task1\_project.py即可。

**2.算法实现**
整体流程如下：
1. 建立动作数据库
2. 初始化动作状态
3. 每播放30帧就根据输入信号的未来期望状态强制搜索一次
4. 将搜索得到的动作状态序列用惯性化与当前动作平滑拼接
5. 连续播放Step4得到的30帧动作并更新角色的根节点全局位置与旋转
6. 重复Step3-5

在建立动作数据库的时候，我采用的动作数据是motion_material / kinematic_motion下的四个长动作与motion_material / idle_.bvh。
对于长动作，我用sub_sequence函数把前后的T-pose剪切扔掉了。但由于只有这四个长动作的时候匹配效果不太理想，于是我进行了数据增广，将这四个动作全部绕Y轴旋转90°得到一组新的动作数据。对于短动作idle_.bvh，我截取中间的一小段建立循环动画后作为被匹配的动作数据。初始化的动作状态是idle动作，并且当角色的期望状态的速度太小就会强制播放idle动作，这个动作比T-pose更自然，这也是为什么我把T-pose删去改换idle动作。动作数据处理好之后，求出根节点和左右脚的逐帧全局旋转、速度、角速度。其中，根节点只考虑Y方向的旋转和角速度，XZ平面的速度。

在搜索的时候，如果期望状态速度大于阈值会在动作数据库中进行搜索。每一帧都计算一个cost，cost由三个部分加权得到，未来30帧的根节点状态匹配差距future_cost、现在动作的根节点状态匹配差距now_cost、现在动作的左右脚状态匹配差距foot_cost。总cost加权公式如下：$$cost=0.3*now\_ cost+0.7*future\_ cost+0.6*foot\_ cost$$ 而由于位置不能保证一致，可能在不同的位置需要匹配相同的动作，为了避免这种情况导致的匹配错误，每一个部分的匹配cost都只由旋转cost、速度cost、角速度cost三个部分组成，不考虑位置的cost，以now_cost的计算为例：$$now\_ cost=now\_ cost\_ rot + now\_ cost\_ vel + now\_ cost\_ avel$$ 而每一个cost的计算都采用作差求模长的方式，例如： $$now\_ cost\_ rot=norm2(rot\_ now-rot\_ desired)$$ 此外，我还对动作的位移(future_pos-now_pos)求了一个cost加到总cost里面，定义同上。

另外，由于未来期望的状态只给出了根节点的相关状态，我单独设置了一个CharacterController类的成员变量用来记录左右脚的当前状态，每次都会用数据库中的对应帧的动作数据的相关信息对其进行更新。为了尽可能减小脚底打滑的状况，根节点的位置更新并未直接设置成未来的期望位置，而是用动作数据库中对应帧的根节点速度求出: $$cur\_ root\_ pos = cur\_ root\_ pos + frame\_ time * DataBase.root\_ vel[cur\_ frame]$$

计算得到所有的cost之后再选取最低的cost对应的动作作为接下来要播放的动作，利用惯性化平滑消除动作转换之间的小差距，消除细微的抖动。

在上面计算cost的过程中，由于我进行了数据增广，需要匹配的动作数据空间比较大，为了加快搜索，我先利用根节点的旋转(即角色朝向)初步筛选可能的匹配动作，然后只针对这些候选动作计算cost。这样能大大减小匹配的计算开销，避免播放动作时因为匹配太慢导致的卡顿。



**3.效果展示**
实现的Motion Matching动作支持建立动作数据库中的一切动作，即长动作走、跑中包含的动作和停止运动原地站立(idle)的动作，包括走、跑、转向、站立不动、侧向运动等，以及这些动作之间的切换。

由于是30帧强制搜索一次，60fps下至多0.5s就能响应控制信号，而正常人的反应速度约0.3s，用户视角下控制效果基本无延迟，能及时响应并播放相应的转向或者其他动作转移的动画。而转向到位的速度取决于平滑后的控制信号输入，由于我改成了substep=15，相对于substep=20而言更小了，优点是这样做能得到更准确的匹配结果，相应的缺点是转向速度会相比substep=20的时候更慢，因为substep=20的时候期望的转向会更接近用户的控制信号。但根据我的实验，在我的设置下已经可以取得非常高的响应速度了，所以综合考虑动作质量和响应速度，我选择改为substep=15。

在不同动作之间的转换也是无缝衔接，非常自然，这得益于惯性化平滑。如果不采用惯性化消除每次搜索得到的动作与当前动作之间的差距，播放出来会出现细微的抖动，这个抖动其实就是动作不完全匹配上的结果，但加上惯性化直接这个差距就被平滑掉了，从而自然平滑的衔接。然而，采用平滑消除差异也有一定的缺点，如果不采用平滑，每一帧播放的动作的根节点位置都是严格按照公式计算得到的，播放的动作就能和原本数据库中的动作一样脚底不打滑。但加上平滑后，根节点的位置是强制设置成计算的结果，并没有与平滑后的结果相统一，这也导致动画会出现少许脚底打滑的现象，匹配差距越大，平滑程度也就越大，打滑的效果就越明显。但总体而言脚底打滑的现象并不明显。

以下是一段demo，可以看到动作非常自然，支持的动作比较丰富，响应速度也很快，转向动作明显，动作转移非常平滑，不存在抖动或者跳变的现象，略有脚底打滑的情况但并不明显，整体而言效果很好。

<p float=left>
<img src='images/demo.gif' width='100%'> 
</p>